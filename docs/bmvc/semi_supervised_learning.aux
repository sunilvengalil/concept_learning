\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{krizhevsky2012imagenet}
\citation{ribeiro2016should}
\citation{lundberg2017unified}
\citation{zhou2016learning}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{kingma2013auto}
\citation{lake2015human}
\citation{lake2015human}
\citation{lake2015human}
\citation{baehrens2010explain}
\citation{ribeiro2016should}
\citation{rabold2019enriching}
\citation{bach2015pixel}
\citation{samek2016evaluating}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\citation{lundberg2017unified}
\citation{zhou2016learning}
\citation{simonyan2014deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of the propsed model. We add an additional loss component at layer 3 of decoder in Variational Autoencoder.\relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{cnn_arch}{{1}{3}{Architecture of the propsed model. We add an additional loss component at layer 3 of decoder in Variational Autoencoder.\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Method}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Network Architecture}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visual concepts generated from each of the digits in MNIST. Since there are two different types of images for digits 4 and 2 separate concepts were generated for each image. The width, height and location of these segments were used to define the mean value of a Normal distribution used for generating more samples.\relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{visual_concept}{{2}{4}{Visual concepts generated from each of the digits in MNIST. Since there are two different types of images for digits 4 and 2 separate concepts were generated for each image. The width, height and location of these segments were used to define the mean value of a Normal distribution used for generating more samples.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Dataset}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Generating Visual Concepts}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Concept Loss}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Generating Training Samples}{5}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussions}{5}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Decoded Cluster center images of latent vectors corresponding to images from original MNIST classes\relax }}{6}{figure.caption.3}\protected@file@percent }
\newlabel{cluster_center_lv_class}{{3}{6}{Decoded Cluster center images of latent vectors corresponding to images from original MNIST classes\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cluster centers of the images corresponding to visual concepts. The images were obtained after clustering latent vectors corresponding to images of visual concepts and then decoding the cluster centers. \relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{cluster_center_lv}{{4}{6}{Cluster centers of the images corresponding to visual concepts. The images were obtained after clustering latent vectors corresponding to images of visual concepts and then decoding the cluster centers. \relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Cluster center images of layer 3 feature maps with concept loss added\relax }}{7}{figure.caption.5}\protected@file@percent }
\newlabel{cluster_center_l3_with_loss}{{5}{7}{Cluster center images of layer 3 feature maps with concept loss added\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Cluster center images of layer 3 feature maps without concept loss\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{cluster_center_l3}{{6}{7}{Cluster center images of layer 3 feature maps without concept loss\relax }{figure.caption.6}{}}
\bibdata{egbib}
\gdef \BMVA@LastPage{8}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{8}{section.5}\protected@file@percent }
