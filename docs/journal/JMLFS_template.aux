\relax 
\citation{jordan2015}
\citation{wu2021}
\citation{lake2015}
\citation{linardatos2021}
\citation{lake2015}
\citation{tenenbaum2019}
\citation{fang2012}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\citation{ribeiro2016should}
\citation{lundberg2017unified}
\citation{zhou2016learning}
\citation{kingma2013auto}
\citation{lake2015}
\citation{lake2015}
\citation{lake2015}
\citation{linardatos2021}
\citation{linardatos2021}
\citation{baehrens2010explain}
\citation{ribeiro2016should}
\citation{rabold2019enriching}
\citation{bach2015pixel}
\citation{samek2016evaluating}
\citation{lundberg2017unified}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Taxonomies of Explainable AI techniques. Image taken from \cite  {linardatos2021}}}{2}\protected@file@percent }
\newlabel{f:explainability_taxonomies}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}\protected@file@percent }
\newlabel{related_work}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Explainability in Deep Learning Models}{2}\protected@file@percent }
\newlabel{lit_survey_explainability}{{2.1}{2}}
\citation{zhou2016learning}
\citation{simonyan2014deep}
\citation{ioffe2015}
\citation{fang2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Concept Learning}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Semi-supervised Learning}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3} PROPOSED METHOD}{3}\protected@file@percent }
\newlabel{proposed_method}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview of Approach}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Datasets}{3}\protected@file@percent }
\bibstyle{unsrt}
\bibcite{jordan2015}{{1}{}{{}}{{}}}
\bibcite{ribeiro2016should}{{2}{}{{}}{{}}}
\bibcite{lundberg2017unified}{{3}{}{{}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of the proposed model for MNIST dataset. An additional loss component were added at layer 3 of decoder in Variational Autoencoder. }}{4}\protected@file@percent }
\newlabel{f:cnn_arch}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visual concepts generated from each of the digits in MNIST. Since there are two different types of images for digits 4 and 2 separate concepts were generated for each image. The width, height and location of these segments were used to define the mean value of a Normal distribution used for generating more samples.}}{4}\protected@file@percent }
\newlabel{f:visual_concept}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Primary Visual Concepts}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Composition of concepts}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Network Architecture, Loss function and Training}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results and Discussion}{4}\protected@file@percent }
\newlabel{results_and_discussion}{{4}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}conclusion}{4}\protected@file@percent }
\newlabel{conclusion}{{5}{4}}
\bibcite{zhou2016learning}{{4}{}{{}}{{}}}
\bibcite{baehrens2010explain}{{5}{}{{}}{{}}}
\bibcite{rabold2019enriching}{{6}{}{{}}{{}}}
\bibcite{bach2015pixel}{{7}{}{{}}{{}}}
\bibcite{samek2016evaluating}{{8}{}{{}}{{}}}
\bibcite{simonyan2014deep}{{9}{}{{}}{{}}}
\bibcite{doshi2017}{{10}{}{{}}{{}}}
\bibcite{linardatos2021}{{11}{}{{}}{{}}}
\bibcite{wu2021}{{12}{}{{}}{{}}}
\bibcite{fang2012}{{13}{}{{}}{{}}}
\bibcite{lake2015}{{14}{}{{}}{{}}}
\bibcite{tenenbaum2019}{{15}{}{{}}{{}}}
\bibcite{nanayakkara2018}{{16}{}{{}}{{}}}
\bibcite{miller2019}{{17}{}{{}}{{}}}
\bibcite{kingma2013auto}{{18}{}{{}}{{}}}
\bibcite{ioffe2015}{{19}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
