{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/supervised_classifier.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "from typing import List, DefaultDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  scipy.signal import correlate2d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "# from numpy.linalg import norm\n",
    "# import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from clearn.experiments.experiment import Experiment, load_trained_model, get_model, get_train_val_iterator, MODEL_TYPE_VAE_SEMI_SUPERVISED_MNIST\n",
    "from clearn.dao.dao_factory import get_dao\n",
    "\n",
    "import tensorflow as tf\n",
    "from clearn.utils.data_loader import TrainValDataIterator, DataIterator\n",
    "from clearn.utils.data_loader import load_images\n",
    "#from clearn.utils.utils import get_latent_vector_column, show_all_variables, get_pmf_y_given_z\n",
    "from clearn.config.common_path import get_encoded_csv_file\n",
    "from clearn.models.classify.classifier import ClassifierModel\n",
    "from clearn.config import ExperimentConfig\n",
    "#from clearn.analysis.cluster_utils import plot_features, trace_dim\n",
    "from matplotlib import pyplot  as  plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z_dim = 10\n",
    "run_id = 41\n",
    "experiment_name = \"semi_supervised_classification\"\n",
    "ROOT_PATH= \"/Users/sunilv/concept_learning_exp\"\n",
    "num_units=[64, 128, 32]\n",
    "#num_units = [16, 32, 8]\n",
    "\n",
    "create_split = False\n",
    "num_cluster_config=ExperimentConfig.NUM_CLUSTERS_CONFIG_ELBOW\n",
    "\n",
    "exp_config = ExperimentConfig(root_path=ROOT_PATH,\n",
    "                               num_decoder_layer=4,\n",
    "                               z_dim=z_dim,\n",
    "                               num_units=num_units,\n",
    "                               num_cluster_config=num_cluster_config,\n",
    "                               confidence_decay_factor=5,\n",
    "                               beta=5,\n",
    "                               supervise_weight=150,\n",
    "                               dataset_name=\"mnist\",\n",
    "                               split_name=\"Split_1\",\n",
    "                               model_name=\"VAE\",\n",
    "                               batch_size=64,\n",
    "                               eval_interval_in_epochs=1,\n",
    "                               name=experiment_name,\n",
    "                               num_val_samples=128,\n",
    "                               total_training_samples=60000,\n",
    "                               manual_labels_config=ExperimentConfig.USE_CLUSTER_CENTER,\n",
    "                               reconstruction_weight=1,\n",
    "                               activation_hidden_layer=\"RELU\",\n",
    "                               activation_output_layer=\"SIGMOID\")\n",
    "exp_config.check_and_create_directories(run_id)\n",
    "BATCH_SIZE = exp_config.BATCH_SIZE\n",
    "DATASET_NAME = exp_config.dataset_name\n",
    "\n",
    "cluster_column_name =\"cluster_level_1\"\n",
    "cluster_column_name_2 =\"cluster_level_2\"\n",
    "cluster_column_name_3 =\"cluster_level_3\"\n",
    "dao = get_dao(exp_config.dataset_name, exp_config.split_name, exp_config.num_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/analysis/manual_annotation_epoch_-1.0.csv path does not exist. Creating random prior with uniform distribution\n"
     ]
    }
   ],
   "source": [
    "train_val_data_iterator = get_train_val_iterator(create_split=create_split,\n",
    "                                                 dao= dao,\n",
    "                                                 exp_config= exp_config,\n",
    "                                                 num_epochs_completed=0,\n",
    "                                                 split_name=exp_config.split_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/semi_supervised_mnist.py:41: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/architectures/custom/tensorflow_graphs.py:11: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/utils/tensorflow_wrappers/layers.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/vae.py:98: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/semi_supervised_mnist.py:127: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/semi_supervised_mnist.py:141: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/semi_supervised_mnist.py:149: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/classify/semi_supervised_mnist.py:155: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/model.py:33: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning/clearn/models/model.py:35: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-4675\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = get_model(dao = dao,\n",
    "              exp_config=exp_config,\n",
    "              model_type=MODEL_TYPE_VAE_SEMI_SUPERVISED_MNIST,\n",
    "              num_epochs=1,\n",
    "              sess=sess,\n",
    "              test_data_iterator=None,\n",
    "              train_val_data_iterator=None)\n",
    "        num_steps_completed = model.counter\n",
    "        print(f\"Number of steps completed={num_steps_completed}\")\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(f\"Number of epochs completed {epochs_completed}\")\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels, manual_annotation_np = load_images(exp_config,\n",
    "                                                           train_val_data_iterator,\n",
    "                                                           \"val\")\n",
    "unique_labels = train_val_data_iterator.get_unique_labels()\n",
    "num_batches = val_images.shape[0] / exp_config.BATCH_SIZE\n",
    "val_labels= np.argwhere(val_labels == 1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(model, images, batch_size, z_dim):\n",
    "    num_images = images.shape[0]\n",
    "    num_batches = num_images // batch_size\n",
    "    batch_num = 0\n",
    "    logits = np.zeros([len(images), z_dim])\n",
    "    print(logits.shape)\n",
    "    print(logits[batch_num * batch_size: (batch_num + 1) * batch_size].shape)\n",
    "    if num_batches >= 1:\n",
    "        # Run for first batch to get the dimensions\n",
    "        batch_num = 0\n",
    "        _logits = model.classify(images[batch_num * batch_size: (batch_num + 1) * batch_size])[0]\n",
    "        print(_logits.shape)\n",
    "        logits[batch_num * batch_size: (batch_num + 1) * batch_size] = _logits\n",
    " \n",
    "        for batch_num in range(1, num_batches):\n",
    "            _logits = model.classify(images[batch_num * batch_size: (batch_num + 1) * batch_size])[0]\n",
    "            logits[batch_num * batch_size: (batch_num + 1) * batch_size] = _logits\n",
    " \n",
    "    left_out = num_images % batch_size\n",
    "    if left_out > 0:\n",
    "        # TODO remove this hard-coding\n",
    "        feature_dimension = [batch_size, 28, 28, 1]\n",
    "        last_batch = np.zeros(feature_dimension)\n",
    "        last_batch[0:left_out] = images[num_batches * batch_size:]\n",
    "        _logits = model.classify(last_batch)[0]\n",
    "        logits[num_batches * batch_size:] = _logits[0:left_out]\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-4675\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n",
      "(128, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = get_model(dao = dao,\n",
    "              exp_config=exp_config,\n",
    "              model_type=MODEL_TYPE_VAE_SEMI_SUPERVISED_MNIST,\n",
    "              num_epochs=1,\n",
    "              sess=sess,\n",
    "              test_data_iterator=None,\n",
    "              train_val_data_iterator=None)\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 6 1 7 7 1 6 0 1 9 1 5 0 9 3 8 3 2 4 4 5 9 9 4 5 3 4 7 5 2 7 4 2 9 7\n",
      " 9 9 7 5 1 2 5 4 5 9 4 6 8 9 3 2 1 3 1 6 3 7 0 5 6 3 3 8 9 4 0 6 0 2 8 8 8\n",
      " 2 2 1 2 2 6 9 1 0 5 2 6 8 3 6 7 7 3 8 7 0 8 3 1 9 9 6 8 0 7 4 5 0 0 8 1 2\n",
      " 3 7 6 1 0 4 0 4 6 1 6 4 7 5 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 8 6 1 7 7 1 6 0 1 4 1 5 0 9 3 8 3 2 9 4 5 9 9 9 1 8 4 7 5 2 7 9 2 4 7\n",
      " 9 9 7 9 1 2 6 9 5 9 4 6 8 7 3 2 1 8 1 2 3 4 0 3 6 8 8 8 9 9 0 6 0 2 8 8 8\n",
      " 2 2 1 8 2 6 9 1 0 3 2 6 8 3 6 7 7 3 8 7 0 8 3 1 4 9 3 8 0 7 4 6 0 0 8 1 2\n",
      " 4 7 6 1 0 9 0 9 6 1 6 4 7 3 8 1 3]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_location = exp_config.DATASET_ROOT_PATH + \"/test/\"\n",
    "test_data_iterator = DataIterator(dataset_path=exp_config.DATASET_ROOT_PATH,\n",
    "                                  batch_size=exp_config.BATCH_SIZE,\n",
    "                                  dao=dao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images, val_labels, manual_annotation_np = load_images(exp_config,\n",
    "                                                           test_data_iterator,\n",
    "                                                           \"test\"\n",
    "                                                          )\n",
    "unique_labels = test_data_iterator.get_unique_labels()\n",
    "num_batches = val_images.shape[0] / exp_config.BATCH_SIZE\n",
    "val_labels= np.argwhere(val_labels == 1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-4675\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-4675\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = get_model(dao = dao,\n",
    "              exp_config=exp_config,\n",
    "              model_type=MODEL_TYPE_VAE_SEMI_SUPERVISED_MNIST,\n",
    "              num_epochs=1,\n",
    "              sess=sess,\n",
    "              test_data_iterator=None,\n",
    "              train_val_data_iterator=None)\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9984, 10)\n",
      "(9984,)\n"
     ]
    }
   ],
   "source": [
    "from  scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7455929487179487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy after epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-936\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-936\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-936\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=936\n",
      "Number of epochs completed 1.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.07421875\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-1870\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-1870\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-1870\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=1870\n",
      "Number of epochs completed 2.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6120793269230769\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-2805\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-2805\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-2805\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=2805\n",
      "Number of epochs completed 3.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6672676282051282\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-3740\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_41/trained_models/SemiSupervisedClassifierMnist.model-3740\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-3740\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=3740\n",
      "Number of epochs completed 4.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.7203525641025641\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-936\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_42/trained_models/SemiSupervisedClassifierMnist.model-936\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-936\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=936\n",
      "Number of epochs completed 1.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.06450320512820513\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-1870\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_42/trained_models/SemiSupervisedClassifierMnist.model-1870\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-1870\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=1870\n",
      "Number of epochs completed 2.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6155849358974359\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-2805\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_42/trained_models/SemiSupervisedClassifierMnist.model-2805\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-2805\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=2805\n",
      "Number of epochs completed 3.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6807892628205128\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "num_training_samples 935\n",
      "ckpt_name SemiSupervisedClassifierMnist.model-3740\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_32_128_64_10_ELBOW_42/trained_models/SemiSupervisedClassifierMnist.model-3740\n",
      " [*] Success to read SemiSupervisedClassifierMnist.model-3740\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=3740\n",
      "Number of epochs completed 4.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.7079326923076923\n"
     ]
    }
   ],
   "source": [
    "run_id_dict = dict()\n",
    "for run_id in [41,42]:\n",
    "    exp_config.check_and_create_directories(run_id)\n",
    "    model = None\n",
    "    tf.reset_default_graph()\n",
    "    val_latent_vectors_by_label = []\n",
    "    val_mu_by_label = []\n",
    "    val_sigma_by_label = []\n",
    "\n",
    "    reconstructed_images = []\n",
    "    images_by_label = []\n",
    "    val_decoder_features = defaultdict(list)\n",
    "    val_encoder_features = defaultdict(list)\n",
    "\n",
    "    reconstructed_images_from_l3 = []\n",
    "    accuracy_dict = dict()\n",
    "    for check_point_epochs in range(1, 5):\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            model = get_model(dao = dao,\n",
    "                              exp_config=exp_config,\n",
    "                              model_type=MODEL_TYPE_VAE_SEMI_SUPERVISED_MNIST,\n",
    "                              num_epochs=1,\n",
    "                              sess=sess,\n",
    "                              test_data_iterator=None,\n",
    "                              train_val_data_iterator=None,\n",
    "                              check_point_epochs=check_point_epochs\n",
    "                             )\n",
    "            num_steps_completed = model.counter\n",
    "            print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "            num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "            epochs_completed = num_steps_completed // num_batches\n",
    "            print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "            logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        pred = softmax(logits)\n",
    "        print(pred.shape)\n",
    "        pred_labels = np.argmax(pred,axis=1)\n",
    "        print(pred_labels.shape)\n",
    "        _acc = accuracy_score(val_labels, pred_labels)\n",
    "        print(_acc)\n",
    "        accuracy_dict[check_point_epochs] = _acc\n",
    "    run_id_dict[run_id] = accuracy_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "plot_filename = \"classification_accuracy.pdf\"\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "for run_id in [41, 42]:\n",
    "    accuracy_dict = run_id_dict[run_id]\n",
    "    plt.plot(list(accuracy_dict.keys()), np.asarray(list(accuracy_dict.values())) * 100, lw=2)\n",
    "axis_font = {'fontname':'Arial', 'size':'12'}\n",
    "\n",
    "plt.xlabel(\"Epochs\", **axis_font)\n",
    "plt.ylabel(\"Accuracy(%)\", **axis_font)\n",
    "\n",
    "plt.xlim(1,6)\n",
    "plt.xticks(ticks = [i for i in range(1,6,1)], labels = [i for i in range(1,6,1)], **axis_font)\n",
    "plt.ylim(0,100)\n",
    "plt.yticks(ticks=[i for i in range(0, 100, 20)], **axis_font)\n",
    "\n",
    "plt.savefig(os.path.join(\"/Users/sunilv/gitprojects/concept_learning/docs/uai2021/\", plot_filename), bbox=\"tight\") \n",
    "\n",
    "    #plt.plot(list(accuracy_dict_unsupervised.keys()), list(accuracy_dict_unsupervised.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"Experiment_1\"\n",
    "z_dim = 10\n",
    "run_id = 0\n",
    "exp_config_unsupervised = ExperimentConfig(root_path=\"/Users/sunilv/concept_learning_exp\",\n",
    "                              num_decoder_layer=4,\n",
    "                              z_dim=z_dim,\n",
    "                              num_units=[64, 128, 32],\n",
    "                              num_cluster_config=None,\n",
    "                              confidence_decay_factor=5,\n",
    "                              beta=5,\n",
    "                              supervise_weight=150,\n",
    "                              dataset_name=\"mnist\",\n",
    "                              split_name=\"Split_1\",\n",
    "                              model_name=\"VAE\",\n",
    "                              batch_size=64,\n",
    "                              eval_interval=300,\n",
    "                              name=experiment_name,\n",
    "                              num_val_samples=128,\n",
    "                              total_training_samples=60000,\n",
    "                              manual_labels_config=TrainValDataIterator.USE_CLUSTER_CENTER,\n",
    "                              reconstruction_weight=1,\n",
    "                              activation_hidden_layer=\"RELU\",\n",
    "                              activation_output_layer=\"SIGMOID\"\n",
    "                              )\n",
    "exp_config_unsupervised.check_and_create_directories(run_id, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-936\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-936\n",
      " [*] Success to read ClassifierModel.model-936\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=936\n",
      "Number of epochs completed 1.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09985977564102565\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-1871\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-1871\n",
      " [*] Success to read ClassifierModel.model-1871\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=1871\n",
      "Number of epochs completed 2.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.10446714743589744\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-2806\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-2806\n",
      " [*] Success to read ClassifierModel.model-2806\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=2806\n",
      "Number of epochs completed 3.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09875801282051282\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-3741\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-3741\n",
      " [*] Success to read ClassifierModel.model-3741\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=3741\n",
      "Number of epochs completed 4.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09875801282051282\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-4676\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-4676\n",
      " [*] Success to read ClassifierModel.model-4676\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4676\n",
      "Number of epochs completed 5.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.0999599358974359\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-5611\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-5611\n",
      " [*] Success to read ClassifierModel.model-5611\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=5611\n",
      "Number of epochs completed 6.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09945913461538461\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "accuracy_dict_unsupervised = dict()\n",
    "for check_point_epochs in range(1, 7):\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            model = ClassifierModel(exp_config_unsupervised,\n",
    "                                    sess,\n",
    "                                    epoch=1,\n",
    "                                    batch_size=exp_config_unsupervised.BATCH_SIZE,\n",
    "                                    z_dim=z_dim,\n",
    "                                    dataset_name=exp_config_unsupervised.dataset_name,\n",
    "                                    beta = exp_config_unsupervised.beta,\n",
    "                                    num_units_in_layer=exp_config_unsupervised.num_units,\n",
    "                                    log_dir=exp_config_unsupervised.LOG_PATH,\n",
    "                                    checkpoint_dir=exp_config_unsupervised.TRAINED_MODELS_PATH,\n",
    "                                    result_dir=exp_config_unsupervised.PREDICTION_RESULTS_PATH,\n",
    "                                    check_point_epochs=check_point_epochs\n",
    "                                   )\n",
    "            num_steps_completed = model.counter\n",
    "            print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "            num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "            epochs_completed = num_steps_completed // num_batches\n",
    "            print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "            logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    pred = softmax(logits)\n",
    "    print(pred.shape)\n",
    "    pred_labels = np.argmax(pred,axis=1)\n",
    "    print(pred_labels.shape)\n",
    "    _acc = accuracy_score(val_labels, pred_labels)\n",
    "    print(_acc)\n",
    "    accuracy_dict_unsupervised[check_point_epochs] = _acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-5611\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_20_32_128_64_10_TWO_TIMES_ELBOW_10/trained_models/ClassifierModel.model-5611",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6fe67f1b61c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINED_MODELS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0mresult_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICTION_RESULTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                 \u001b[0mcheck_point_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_point_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                                )\n\u001b[1;32m     17\u001b[0m         \u001b[0mnum_steps_completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, exp_config, sess, epoch, batch_size, z_dim, dataset_name, beta, num_units_in_layer, log_dir, checkpoint_dir, result_dir, train_val_data_iterator, read_from_existing_checkpoint, check_point_epochs, supervise_weight, reconstruction_weight, reconstructed_image_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         self.counter, self.start_batch_id, self.start_epoch = self._initialize(train_val_data_iterator,\n\u001b[1;32m     81\u001b[0m                                                                                \u001b[0mread_from_existing_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                                                                check_point_epochs)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#   Gaussian Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, train_val_data_iterator, restore_from_existing_checkpoint, check_point_epochs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# restore check-point if it exits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             could_load, checkpoint_counter = self._load(self.checkpoint_dir,\n\u001b[0;32m--> 293\u001b[0;31m                                                         check_point_epochs=check_point_epochs)\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcould_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrain_val_data_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, checkpoint_dir, check_point_epochs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mckpt_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"ClassifierModel.model-{steps}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ckpt_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(\\d+)(?!.*\\d)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" [*] Success to read {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m-> 1278\u001b[0;31m                        compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_20_32_128_64_10_TWO_TIMES_ELBOW_10/trained_models/ClassifierModel.model-5611"
     ]
    }
   ],
   "source": [
    "check_point_epochs = 6\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH,\n",
    "                                check_point_epochs=check_point_epochs\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)\n",
    "print(accuracy_score(val_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09134615384615384\n"
     ]
    }
   ],
   "source": [
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_split = False\n",
    "z_dim = 10\n",
    "experiment_name = \"supervised_classification\"\n",
    "num_epochs = 10\n",
    "num_cluster_config = ExperimentConfig.NUM_CLUSTERS_CONFIG_TWO_TIMES_ELBOW\n",
    "run_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, exp_config = load_trained_model(experiment_name,\n",
    "                         z_dim,\n",
    "                         run_id,\n",
    "                         num_cluster_config,\n",
    "                         manual_labels_config=TrainValDataIterator.USE_ACTUAL,\n",
    "                         supervise_weight=1,\n",
    "                         beta=0,\n",
    "                         reconstruction_weight=0,\n",
    "                         model_type=MODEL_TYPE_SUPERVISED_CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
