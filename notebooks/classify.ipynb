{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "from typing import List, DefaultDict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  scipy.signal import correlate2d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "# from numpy.linalg import norm\n",
    "# import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from clearn.experiments.experiment import Experiment, load_trained_model\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from clearn.utils.data_loader import TrainValDataIterator\n",
    "from clearn.utils.data_loader import load_images\n",
    "#from clearn.utils.utils import get_latent_vector_column, show_all_variables, get_pmf_y_given_z\n",
    "from clearn.config.common_path import get_encoded_csv_file\n",
    "from clearn.models.classify.classifier import ClassifierModel\n",
    "from clearn.config import ExperimentConfig\n",
    "#from clearn.analysis.cluster_utils import plot_features, trace_dim\n",
    "from matplotlib import pyplot  as  plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 10\n",
    "run_id = 13\n",
    "experiment_name = \"semi_supervised_classification_published\"\n",
    "ROOT_PATH= \"/Users/sunilv/concept_learning_exp\"\n",
    "num_units=[64, 128, 32]\n",
    "#num_units = [16, 32, 8]\n",
    "\n",
    "create_split = False\n",
    "num_cluster_config=ExperimentConfig.NUM_CLUSTERS_CONFIG_ELBOW\n",
    "\n",
    "exp_config = ExperimentConfig(root_path=ROOT_PATH,\n",
    "                               num_decoder_layer=4,\n",
    "                               z_dim=z_dim,\n",
    "                               num_units=num_units,\n",
    "                               num_cluster_config=num_cluster_config,\n",
    "                               confidence_decay_factor=5,\n",
    "                               beta=5,\n",
    "                               supervise_weight=150,\n",
    "                               dataset_name=\"mnist\",\n",
    "                               split_name=\"Split_1\",\n",
    "                               model_name=\"VAE\",\n",
    "                               batch_size=64,\n",
    "                               eval_interval=300,\n",
    "                               name=experiment_name,\n",
    "                               num_val_samples=128,\n",
    "                               total_training_samples=60000,\n",
    "                               manual_labels_config=TrainValDataIterator.USE_CLUSTER_CENTER,\n",
    "                               reconstruction_weight=1,\n",
    "                               activation_hidden_layer=\"RELU\",\n",
    "                               activation_output_layer=\"SIGMOID\")\n",
    "exp_config.check_and_create_directories(run_id, False)\n",
    "BATCH_SIZE = exp_config.BATCH_SIZE\n",
    "DATASET_NAME = exp_config.dataset_name\n",
    "\n",
    "cluster_column_name =\"cluster_level_1\"\n",
    "cluster_column_name_2 =\"cluster_level_2\"\n",
    "cluster_column_name_3 =\"cluster_level_3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 128, 32, 20]\n",
      "/Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def get_base_path(exp_config,\n",
    "                  run_id: int = 0\n",
    "                  ) -> str:\n",
    "    \"\"\"\n",
    "    :rtype:\n",
    "    \"\"\"\n",
    "\n",
    "    num_units = exp_config.num_units\n",
    "    print(num_units)\n",
    "    if len(exp_config.num_units)  >= 3:\n",
    "        units_ = str(exp_config.num_units[-1])\n",
    "        for i in exp_config.num_units[2:-1][::-1]:\n",
    "            units_ += \"_\" + str(i)\n",
    "    else:\n",
    "        units_ = \"0\"\n",
    "    if exp_config.num_cluster_config is None:\n",
    "        return os.path.join(os.path.join(exp_config.root_path, exp_config.name), f\"Exp_{units_}_{num_units[1]}_{num_units[0]}_{exp_config.Z_DIM}_{run_id}/\")\n",
    "    else:\n",
    "        return os.path.join(os.path.join(exp_config.root_path, exp_config.name), f\"Exp_{units_}_{num_units[1]}_{num_units[0]}_{exp_config.Z_DIM}_{exp_config.num_cluster_config}_{run_id}/\")\n",
    "print(get_base_path(exp_config, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:70: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:89: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/utils/tensorflow_wrappers/layers.py:39: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:169: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:173: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:183: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:204: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:213: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:220: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:281: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/sunilv/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py:283: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-4675\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-4675\n",
      " [*] Success to read ClassifierModel.model-4675\n",
      " [*] Load SUCCESS\n",
      "[<tf.Variable 'encoder/en_conv1/w:0' shape=(3, 3, 1, 64) dtype=float32_ref>, <tf.Variable 'encoder/en_conv1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'encoder/en_conv2/w:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'encoder/en_conv2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'encoder/en_fc3/Matrix:0' shape=(6272, 32) dtype=float32_ref>, <tf.Variable 'encoder/en_fc3/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'encoder/en_fc4/Matrix:0' shape=(32, 20) dtype=float32_ref>, <tf.Variable 'encoder/en_fc4/bias:0' shape=(20,) dtype=float32_ref>, <tf.Variable 'Linear/Matrix:0' shape=(10, 10) dtype=float32_ref>, <tf.Variable 'Linear/bias:0' shape=(10,) dtype=float32_ref>, <tf.Variable 'decoder/de_fc1/Matrix:0' shape=(10, 32) dtype=float32_ref>, <tf.Variable 'decoder/de_fc1/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'decoder/Linear/Matrix:0' shape=(32, 6272) dtype=float32_ref>, <tf.Variable 'decoder/Linear/bias:0' shape=(6272,) dtype=float32_ref>, <tf.Variable 'decoder/de_dc3/w:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'decoder/de_dc3/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'decoder/de_dc4/w:0' shape=(3, 3, 1, 64) dtype=float32_ref>, <tf.Variable 'decoder/de_dc4/biases:0' shape=(1,) dtype=float32_ref>]\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH\n",
    "                               )\n",
    "        print(model.get_trainable_vars())\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        encoder_params = model.get_encoder_weights_bias()\n",
    "        decoder_params =model.get_decoder_weights_bias()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cluster center\n",
      "Warning None path does not exist. Creating random prior with uniform distribution\n"
     ]
    }
   ],
   "source": [
    "train_val_iterator, val_images, val_labels, manual_annotation_np = load_images(exp_config,\n",
    "                                                                    \"val\")\n",
    "unique_labels = train_val_iterator.get_unique_labels()\n",
    "num_batches = val_images.shape[0] / exp_config.BATCH_SIZE\n",
    "val_labels= np.argwhere(val_labels == 1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(model, images, batch_size, z_dim):\n",
    "    num_images = images.shape[0]\n",
    "    num_batches = num_images // batch_size\n",
    "    batch_num = 0\n",
    "    logits = np.zeros([len(images), z_dim])\n",
    "    print(logits.shape)\n",
    "    print(logits[batch_num * batch_size: (batch_num + 1) * batch_size].shape)\n",
    "    if num_batches >= 1:\n",
    "        # Run for first batch to get the dimensions\n",
    "        batch_num = 0\n",
    "        _logits = model.classify(images[batch_num * batch_size: (batch_num + 1) * batch_size])[0]\n",
    "        print(_logits.shape)\n",
    "        logits[batch_num * batch_size: (batch_num + 1) * batch_size] = _logits\n",
    " \n",
    "        for batch_num in range(1, num_batches):\n",
    "            _logits = model.classify(images[batch_num * batch_size: (batch_num + 1) * batch_size])[0]\n",
    "            logits[batch_num * batch_size: (batch_num + 1) * batch_size] = _logits\n",
    " \n",
    "    left_out = num_images % batch_size\n",
    "    if left_out > 0:\n",
    "        # TODO remove this hard-coding\n",
    "        feature_dimension = [batch_size, 28, 28, 1]\n",
    "        last_batch = np.zeros(feature_dimension)\n",
    "        last_batch[0:left_out] = images[num_batches * batch_size:]\n",
    "        _logits = model.classify(last_batch)[0]\n",
    "        logits[num_batches * batch_size:] = _logits[0:left_out]\n",
    "\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-4675\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-4675\n",
      " [*] Success to read ClassifierModel.model-4675\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n",
      "(128, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10)\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6953125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 6 1 7 7 1 6 0 1 9 1 5 0 9 3 8 3 2 4 4 5 9 9 4 5 3 4 7 5 2 7 4 2 9 7\n",
      " 9 9 7 5 1 2 5 4 5 9 4 6 8 9 3 2 1 3 1 6 3 7 0 5 6 3 3 8 9 4 0 6 0 2 8 8 8\n",
      " 2 2 1 2 2 6 9 1 0 5 2 6 8 3 6 7 7 3 8 7 0 8 3 1 9 9 6 8 0 7 4 5 0 0 8 1 2\n",
      " 3 7 6 1 0 4 0 4 6 1 6 4 7 5 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 8 6 1 9 4 1 6 0 1 4 1 8 0 9 3 8 3 2 9 9 8 9 9 9 8 8 9 7 8 2 4 9 2 4 7\n",
      " 9 9 7 8 1 2 6 9 8 9 9 6 8 7 8 2 1 8 1 6 3 4 0 3 6 3 1 8 9 9 0 6 0 2 8 8 8\n",
      " 2 2 1 8 2 6 9 1 0 3 2 6 8 3 6 7 7 3 8 7 0 8 8 1 4 9 6 8 0 7 9 1 0 0 8 1 2\n",
      " 3 7 6 1 0 6 0 9 6 1 6 9 7 3 8 1 8]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split percent is zero\n",
      "Warning None path does not exist. Creating random prior with uniform distribution\n"
     ]
    }
   ],
   "source": [
    "train_val_iterator, val_images, val_labels, manual_annotation_np = load_images(exp_config,\n",
    "                                                                    \"test\")\n",
    "unique_labels = train_val_iterator.get_unique_labels()\n",
    "num_batches = val_images.shape[0] / exp_config.BATCH_SIZE\n",
    "val_labels= np.argwhere(val_labels == 1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-4675\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-4675\n",
      " [*] Success to read ClassifierModel.model-4675\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4675\n",
      "Number of epochs completed 5.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9984, 10)\n",
      "(9984,)\n"
     ]
    }
   ],
   "source": [
    "from  scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6907051282051282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy after epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-936\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-936\n",
      " [*] Success to read ClassifierModel.model-936\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=936\n",
      "Number of epochs completed 1.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.10927483974358974\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-1870\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-1870\n",
      " [*] Success to read ClassifierModel.model-1870\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=1870\n",
      "Number of epochs completed 2.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.5802283653846154\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-2805\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-2805\n",
      " [*] Success to read ClassifierModel.model-2805\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=2805\n",
      "Number of epochs completed 3.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6816907051282052\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-3740\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/semi_supervised_classification_published/Exp_20_32_128_64_10_ELBOW_13/trained_models/ClassifierModel.model-3740\n",
      " [*] Success to read ClassifierModel.model-3740\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=3740\n",
      "Number of epochs completed 4.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.6894030448717948\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "accuracy_dict = dict()\n",
    "for check_point_epochs in range(1, 5):\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            model = ClassifierModel(exp_config,\n",
    "                                    sess,\n",
    "                                    epoch=1,\n",
    "                                    batch_size=exp_config.BATCH_SIZE,\n",
    "                                    z_dim=z_dim,\n",
    "                                    dataset_name=exp_config.dataset_name,\n",
    "                                    beta = exp_config.beta,\n",
    "                                    num_units_in_layer=exp_config.num_units,\n",
    "                                    log_dir=exp_config.LOG_PATH,\n",
    "                                    checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                    result_dir=exp_config.PREDICTION_RESULTS_PATH,\n",
    "                                    check_point_epochs=check_point_epochs\n",
    "                                   )\n",
    "            num_steps_completed = model.counter\n",
    "            print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "            num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "            epochs_completed = num_steps_completed // num_batches\n",
    "            print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "            logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    pred = softmax(logits)\n",
    "    print(pred.shape)\n",
    "    pred_labels = np.argmax(pred,axis=1)\n",
    "    print(pred_labels.shape)\n",
    "    _acc = accuracy_score(val_labels, pred_labels)\n",
    "    print(_acc)\n",
    "    accuracy_dict[check_point_epochs] = _acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "plot_filename = \"classification_accuracy.pdf\"\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "\n",
    "plt.plot(list(accuracy_dict.keys()), np.asarray(list(accuracy_dict.values())) * 100, lw=2)\n",
    "axis_font = {'fontname':'Arial', 'size':'12'}\n",
    "\n",
    "plt.xlabel(\"Epochs\", **axis_font)\n",
    "plt.ylabel(\"Accuracy(%)\", **axis_font)\n",
    "\n",
    "plt.xlim(1,6)\n",
    "plt.xticks(ticks = [i for i in range(1,6,1)], labels = [i for i in range(1,6,1)], **axis_font)\n",
    "plt.ylim(0,100)\n",
    "plt.yticks(ticks=[i for i in range(0, 100, 20)], **axis_font)\n",
    "plt.savefig(os.path.join(\"/Users/sunilv/gitprojects/concept_learning/docs/uai2021/\", plot_filename), bbox=\"tight\") \n",
    "\n",
    "#plt.plot(list(accuracy_dict_unsupervised.keys()), list(accuracy_dict_unsupervised.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"Experiment_1\"\n",
    "z_dim = 10\n",
    "run_id = 0\n",
    "exp_config_unsupervised = ExperimentConfig(root_path=\"/Users/sunilv/concept_learning_exp\",\n",
    "                              num_decoder_layer=4,\n",
    "                              z_dim=z_dim,\n",
    "                              num_units=[64, 128, 32],\n",
    "                              num_cluster_config=None,\n",
    "                              confidence_decay_factor=5,\n",
    "                              beta=5,\n",
    "                              supervise_weight=150,\n",
    "                              dataset_name=\"mnist\",\n",
    "                              split_name=\"Split_1\",\n",
    "                              model_name=\"VAE\",\n",
    "                              batch_size=64,\n",
    "                              eval_interval=300,\n",
    "                              name=experiment_name,\n",
    "                              num_val_samples=128,\n",
    "                              total_training_samples=60000,\n",
    "                              manual_labels_config=TrainValDataIterator.USE_CLUSTER_CENTER,\n",
    "                              reconstruction_weight=1,\n",
    "                              activation_hidden_layer=\"RELU\",\n",
    "                              activation_output_layer=\"SIGMOID\"\n",
    "                              )\n",
    "exp_config_unsupervised.check_and_create_directories(run_id, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-936\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-936\n",
      " [*] Success to read ClassifierModel.model-936\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=936\n",
      "Number of epochs completed 1.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09985977564102565\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-1871\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-1871\n",
      " [*] Success to read ClassifierModel.model-1871\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=1871\n",
      "Number of epochs completed 2.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.10446714743589744\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-2806\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-2806\n",
      " [*] Success to read ClassifierModel.model-2806\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=2806\n",
      "Number of epochs completed 3.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09875801282051282\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-3741\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-3741\n",
      " [*] Success to read ClassifierModel.model-3741\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=3741\n",
      "Number of epochs completed 4.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09875801282051282\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-4676\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-4676\n",
      " [*] Success to read ClassifierModel.model-4676\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=4676\n",
      "Number of epochs completed 5.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.0999599358974359\n",
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-5611\n",
      "INFO:tensorflow:Restoring parameters from /Users/sunilv/concept_learning_exp/Experiment_1/Exp_20_32_128_64_10_0/trained_models/ClassifierModel.model-5611\n",
      " [*] Success to read ClassifierModel.model-5611\n",
      " [*] Load SUCCESS\n",
      "Number of steps completed=5611\n",
      "Number of epochs completed 6.0\n",
      "(9984, 10)\n",
      "(64, 10)\n",
      "(64, 10)\n",
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09945913461538461\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "accuracy_dict_unsupervised = dict()\n",
    "for check_point_epochs in range(1, 7):\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            model = ClassifierModel(exp_config_unsupervised,\n",
    "                                    sess,\n",
    "                                    epoch=1,\n",
    "                                    batch_size=exp_config_unsupervised.BATCH_SIZE,\n",
    "                                    z_dim=z_dim,\n",
    "                                    dataset_name=exp_config_unsupervised.dataset_name,\n",
    "                                    beta = exp_config_unsupervised.beta,\n",
    "                                    num_units_in_layer=exp_config_unsupervised.num_units,\n",
    "                                    log_dir=exp_config_unsupervised.LOG_PATH,\n",
    "                                    checkpoint_dir=exp_config_unsupervised.TRAINED_MODELS_PATH,\n",
    "                                    result_dir=exp_config_unsupervised.PREDICTION_RESULTS_PATH,\n",
    "                                    check_point_epochs=check_point_epochs\n",
    "                                   )\n",
    "            num_steps_completed = model.counter\n",
    "            print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "            num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "            epochs_completed = num_steps_completed // num_batches\n",
    "            print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "            logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    pred = softmax(logits)\n",
    "    print(pred.shape)\n",
    "    pred_labels = np.argmax(pred,axis=1)\n",
    "    print(pred_labels.shape)\n",
    "    _acc = accuracy_score(val_labels, pred_labels)\n",
    "    print(_acc)\n",
    "    accuracy_dict_unsupervised[check_point_epochs] = _acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name Negative Log Likelihood is illegal; using Negative_Log_Likelihood instead.\n",
      "INFO:tensorflow:Summary name K L Divergence is illegal; using K_L_Divergence instead.\n",
      "INFO:tensorflow:Summary name Supervised Loss is illegal; using Supervised_Loss instead.\n",
      "INFO:tensorflow:Summary name Total Loss is illegal; using Total_Loss instead.\n",
      " [*] Reading checkpoints...\n",
      "ckpt_name ClassifierModel.model-5611\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The passed save_path is not a valid checkpoint: /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_20_32_128_64_10_TWO_TIMES_ELBOW_10/trained_models/ClassifierModel.model-5611",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6fe67f1b61c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINED_MODELS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0mresult_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICTION_RESULTS_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                 \u001b[0mcheck_point_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_point_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                                )\n\u001b[1;32m     17\u001b[0m         \u001b[0mnum_steps_completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, exp_config, sess, epoch, batch_size, z_dim, dataset_name, beta, num_units_in_layer, log_dir, checkpoint_dir, result_dir, train_val_data_iterator, read_from_existing_checkpoint, check_point_epochs, supervise_weight, reconstruction_weight, reconstructed_image_dir)\u001b[0m\n\u001b[1;32m     80\u001b[0m         self.counter, self.start_batch_id, self.start_epoch = self._initialize(train_val_data_iterator,\n\u001b[1;32m     81\u001b[0m                                                                                \u001b[0mread_from_existing_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                                                                check_point_epochs)\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#   Gaussian Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, train_val_data_iterator, restore_from_existing_checkpoint, check_point_epochs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# restore check-point if it exits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             could_load, checkpoint_counter = self._load(self.checkpoint_dir,\n\u001b[0;32m--> 293\u001b[0;31m                                                         check_point_epochs=check_point_epochs)\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcould_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrain_val_data_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gitprojects/concept_learning_mnist/concept_learning/clearn/models/classify/classifier.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, checkpoint_dir, check_point_epochs)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0mckpt_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"ClassifierModel.model-{steps}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ckpt_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"(\\d+)(?!.*\\d)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" [*] Success to read {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m-> 1278\u001b[0;31m                        compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: /Users/sunilv/concept_learning_exp/semi_supervised_classification/Exp_20_32_128_64_10_TWO_TIMES_ELBOW_10/trained_models/ClassifierModel.model-5611"
     ]
    }
   ],
   "source": [
    "check_point_epochs = 6\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH,\n",
    "                                check_point_epochs=check_point_epochs\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)\n",
    "print(accuracy_score(val_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9984, 10)\n",
      "(9984,)\n",
      "0.09134615384615384\n"
     ]
    }
   ],
   "source": [
    "pred = softmax(logits)\n",
    "print(pred.shape)\n",
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_split = False\n",
    "z_dim = 10\n",
    "experiment_name = \"supervised_classification\"\n",
    "num_epochs = 10\n",
    "num_cluster_config = ExperimentConfig.NUM_CLUSTERS_CONFIG_TWO_TIMES_ELBOW\n",
    "run_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, exp_config = load_trained_model(experiment_name,\n",
    "                         z_dim,\n",
    "                         run_id,\n",
    "                         num_cluster_config,\n",
    "                         manual_labels_config=TrainValDataIterator.USE_ACTUAL,\n",
    "                         supervise_weight=1,\n",
    "                         beta=0,\n",
    "                         reconstruction_weight=0,\n",
    "                         model_type=MODEL_TYPE_SUPERVISED_CLASSIFIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "tf.reset_default_graph()\n",
    "val_latent_vectors_by_label = []\n",
    "val_mu_by_label = []\n",
    "val_sigma_by_label = []\n",
    "\n",
    "reconstructed_images = []\n",
    "images_by_label = []\n",
    "val_decoder_features = defaultdict(list)\n",
    "val_encoder_features = defaultdict(list)\n",
    "\n",
    "reconstructed_images_from_l3 = []\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        model = ClassifierModel(exp_config,\n",
    "                                sess,\n",
    "                                epoch=1,\n",
    "                                batch_size=exp_config.BATCH_SIZE,\n",
    "                                z_dim=z_dim,\n",
    "                                dataset_name=exp_config.dataset_name,\n",
    "                                beta = exp_config.beta,\n",
    "                                num_units_in_layer=exp_config.num_units,\n",
    "                                log_dir=exp_config.LOG_PATH,\n",
    "                                checkpoint_dir=exp_config.TRAINED_MODELS_PATH,\n",
    "                                result_dir=exp_config.PREDICTION_RESULTS_PATH\n",
    "                               )\n",
    "        num_steps_completed = model.counter\n",
    "        print(\"Number of steps completed={}\".format(num_steps_completed))\n",
    "        num_batches = exp_config.num_train_samples / exp_config.BATCH_SIZE\n",
    "        epochs_completed = num_steps_completed // num_batches\n",
    "        print(\"Number of epochs completed {}\".format(epochs_completed))\n",
    "        logits = classify_images(model, val_images, exp_config.BATCH_SIZE, exp_config.Z_DIM)\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "pred = softmax(logits)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(pred,axis=1)\n",
    "print(pred_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
